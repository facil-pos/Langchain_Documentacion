{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices\n",
    "\n",
    "* [Variables de entorno](#variables-de-entorno)\n",
    "* [Intalacion de paquetes](#instalcion-de-pequetes-necesarios)\n",
    "* [LLM / Chat Model](#llm--chat-model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables de entorno\n",
    "Usaremos la API de OpenIA para esto cargaremos nuestras variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (22.0.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.0.2\n",
      "    Uninstalling pip-22.0.2:\n",
      "      Successfully uninstalled pip-22.0.2\n",
      "Successfully installed pip-24.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key=os.getenv('GEMINI_API_KEY_2', 'YourAPIKey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalcion de pequetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
      "  Downloading langchain_core-0.3.18-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.143-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.15->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting sniffio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.18-py3-none-any.whl (409 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.143-py3-none-any.whl (306 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading orjson-3.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: urllib3, tenacity, sniffio, PyYAML, pydantic-core, propcache, orjson, numpy, multidict, jsonpointer, idna, h11, greenlet, frozenlist, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, httpx, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.11.2 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.2.post1 async-timeout-4.0.3 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.7 langchain-core-0.3.18 langchain-text-splitters-0.3.2 langsmith-0.1.143 multidict-6.1.0 numpy-1.26.4 orjson-3.10.11 propcache-0.2.0 pydantic-2.9.2 pydantic-core-2.23.4 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 urllib3-2.2.3 yarl-1.17.1\n",
      "Requirement already satisfied: langchain-core in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (0.3.18)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langchain-core) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langchain-core) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (3.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.23.4)\n",
      "Requirement already satisfied: anyio in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (2.2.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.2.2)\n",
      "Requirement already satisfied: google-generativeai in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-generativeai) (2.23.0)\n",
      "Requirement already satisfied: google-api-python-client in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-generativeai) (2.153.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-generativeai) (2.36.0)\n",
      "Requirement already satisfied: protobuf in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-generativeai) (5.28.3)\n",
      "Requirement already satisfied: pydantic in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-generativeai) (2.9.2)\n",
      "Requirement already satisfied: tqdm in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-generativeai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.23.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.67.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dannkol/Langchain_Documentacion/.venv/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install -qU langchain-google-genai\n",
    "!pip install langchain-core\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM / Chat Model\n",
    "\n",
    "Langchain nos permite trabajar con dos tipos de modelos de languaje\n",
    "\n",
    "* `llms`: Los LLM son modelos lingüísticos de propósito general que pueden utilizarse para diversas tareas de procesamiento del lenguaje natural, como la generación de texto, el resumen o la traducción, entre otras. Están diseñados para procesar entradas de texto y generar salidas de texto. El módulo llms proporciona funcionalidad relacionada con el trabajo con LLMs, como cargar modelos, realizar inferencias y gestionar configuraciones de modelos.\n",
    "\n",
    "* `chat_models`: Los modelos de chat son un tipo específico de modelo lingüístico diseñado para aplicaciones conversacionales. Están entrenados para comprender y generar respuestas en el contexto de una conversación. El módulo chat_models proporciona funcionalidad específica a los modelos de chat, como el manejo de conversaciones basadas en chat, la gestión de sesiones de chat y la generación de respuestas basadas en el historial de conversaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametros de las instancias\n",
    "\n",
    "- ``model_name``: Especifica el nombre del modelo de chat a utilizar, como \"gemini-1.5-flash\".\n",
    "- ``max_tokens``: Establece el número máximo de tokens a generar en la respuesta.\n",
    "- ``temperature``: Controla la aleatoriedad de la salida generada. Los valores más altos (por ejemplo, 0,8) hacen que la salida sea más aleatoria, mientras que los valores más bajos (por ejemplo, 0,2) la hacen más centrada y determinista.\n",
    "- ``n``: Especifica el número de finalizaciones de chat que se generarán para cada pregunta.\n",
    "- ``stop``: Define una lista de cadenas que, si se encuentran en la salida generada, indicarán al modelo que deje de generar más texto.\n",
    "- ``metadata``: Permite añadir metadatos a la traza de ejecución, lo que puede resultar útil para seguir y organizar las salidas del modelo.\n",
    "- ``tags``: Proporciona una lista de etiquetas para añadir a la traza de ejecución, lo que permite una categorización y filtrado más sencillos de las salidas del modelo.\n",
    "- ``callbacks``: Permite añadir retrollamadas a la traza de ejecución, lo que permite realizar acciones personalizadas durante el proceso de generación.\n",
    "- ``verbose``: Controla si se imprime el texto de respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de uso de [`chat models`](https://python.langchain.com/docs/integrations/chat/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esquemas\n",
    "\n",
    "LangChain proporciona varios objetos para distinguir fácilmente entre diferentes roles en una conversación. Estos objetos son útiles al trabajar con modelos de lenguaje basados en chat y permiten especificar el rol de cada mensaje en la conversación. Algunos de estos objetos son:\n",
    "\n",
    "* HumanMessage: Representa un mensaje enviado por un humano o usuario en la conversación.\n",
    "* AIMessage: Representa un mensaje generado por un modelo de lenguaje o asistente de inteligencia artificial.\n",
    "*  SystemMessage: Representa un mensaje generado por el sistema o utilizado para configurar el comportamiento del modelo.\n",
    "* FunctionMessage: Representa un mensaje generado como resultado de la ejecución de una función en la cadena.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Unos pantalones vaqueros oscuros o unos pantalones de lana grises quedarían genial con tu abrigo azul!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Creamos una instancia de ChatOpenAI\n",
    "# system_instruction este nos permite \n",
    "chat_model = GoogleGenerativeAI(temperature=0, model=\"gemini-1.5-flash-latest\", google_api_key=gemini_api_key)\n",
    "\n",
    "# Definimos la conversación con sus roles\n",
    "conversation = [\n",
    "    SystemMessage(content=\"Eres un simpático bot de inteligencia artificial que ayuda a un usuario a saber qué ropa usar en una frase corta\"),\n",
    "    HumanMessage(content=\"Me gusta el color azul, ¿qué debería usar en un clima frío?\"),\n",
    "    AIMessage(content=\"Podrías usar un abrigo azul\"),\n",
    "    HumanMessage(content=\"¿Con qué más lo combino?\")\n",
    "]\n",
    "\n",
    "# Genera una respuesta basada en la conversación\n",
    "response = chat_model.invoke(conversation)\n",
    "\n",
    "# Imprime la respuesta\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Eres un simpático bot de inteligencia artificial que ayuda a un usuario a saber qué ropa usar en una frase corta',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'system',\n",
       " 'name': None,\n",
       " 'id': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "System = conversation[0]\n",
    "System.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentos\n",
    "\n",
    "Anteriormente definimos que langchain usa tipos de objetos para definir o diferneciar roles, entre estos esta el objeto Document, Objeto que contiene un texto y metadatos (más información sobre ese texto).\n",
    "\n",
    "Al crear una instancia de Document, puedes proporcionar el contenido del texto y los metadatos opcionales en forma de un diccionario. Algunos ejemplos de metadatos podrían ser la fuente del contenido, las relaciones con otros documentos, entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este es el contenido del documento\n",
      "{'fuente': 'ejemplo', 'autor': 'Daniel', 'referencia': 'https://chat.langchain.com/'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Crear una instancia de Document\n",
    "doc = Document(page_content=\"Este es el contenido del documento\", metadata={\"fuente\": \"ejemplo\",\"autor\":\"Daniel\",\"referencia\":\"https://chat.langchain.com/\"})\n",
    "\n",
    "# Acceder al contenido del documento\n",
    "print(doc.page_content)  # \"Este es el contenido del documento\"\n",
    "\n",
    "# Acceder a los metadatos del documento\n",
    "print(doc.metadata)  # {\"fuente\": \"ejemplo\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
