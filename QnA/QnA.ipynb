{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalcion de pinecon\n",
    "!pip install pypdf cohere tiktoken langchain sentence_transformers openai pinecone-client -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miselanea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para calcular el costo de los embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embeddings_cost(texts):\n",
    "  import tiktoken\n",
    "  enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "  total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "  print(f'Total Tokens: {total_tokens}')\n",
    "  print(f'Embeddings consto en dolar:  {total_tokens / 1000 * 0.0001:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "INDEX_NAME = 'taller'\n",
    "\n",
    "openai_api_key=os.getenv('OPENAI_API_KEY', 'YourAPIKey')\n",
    "pinecone_api_key=os.getenv('PINECONE_API_KEY', 'YourAPIKey')\n",
    "pinecone_environment=os.getenv('PINECONE_ENVIRONMENT', 'YourEnvironment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga de archivos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Fichero PDF\n",
    "archivos_url = [\"https://preguntapdf.s3.eu-south-2.amazonaws.com/la-rosaleda_v3.pdf\"]\n",
    "\n",
    "for url in archivos_url:\n",
    "    doc_to_download = requests.get(url)\n",
    "    # Guardar fichero\n",
    "    pdf_file = open(url.split(\"/\")[-1], \"wb\")\n",
    "    pdf_file.write(doc_to_download.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuracion de pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion del indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taller']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La dimension y la metric estan dadas por el vector creado por nuesto modelo de embedding -> OpenAI/text-embedding-ada-002\n",
    "pinecone.create_index(INDEX_NAME, dimension=1536, metric=\"cosine\")\n",
    "# listar indice\n",
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos su descripcion\n",
    "collection_description = pinecone.describe_index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexDescription(name='taller', metric='cosine', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes necesarios\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del archivo\n",
    "FILE = \"la-rosaleda_v3.pdf\"\n",
    "loader = PyPDFLoader(FILE)\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes necesarios\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecursiveCharacterTextSplitter\n",
    "\n",
    "Anteriormente habiamos visto metodos CharacterTextSplitter para la creacion de chunk o dividir los textos en este caso haremos uso de RecursiveCharacterTextSplitter que no es más que una forma recursiva para dividir los textos, estos nos permite que los fragmentos dividos mantengan un sentido en el contexto general "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion creadora de chunk\n",
    "def create_chunks(doc_to_chunk):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len\n",
    "        )\n",
    "    return text_splitter.split_documents(doc_to_chunk)\n",
    "\n",
    "chunks = create_chunks(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes necesrios\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcula el costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 1621\n",
      "Embeddings consto en dolar:  0.00016\n"
     ]
    }
   ],
   "source": [
    "print_embeddings_cost(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga el modelo de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de los embeddings a pinecone\n",
    "\n",
    "Pinecone.from_documents es un método en la clase Pinecone de la biblioteca Langchain que se utiliza para inicializar un objeto Pinecone a partir de una lista de documentos y embeddings. Aquí están todos los parámetros que se pueden pasar a este método:\n",
    "\n",
    "* documents (List[Document]): Una lista de objetos Document que representan los documentos que se agregarán al vectorstore de Pinecone.\n",
    "* embedding (Embeddings): Un objeto de embeddings que se utilizará para calcular los vectores de los documentos.\n",
    "* metadatas (Optional[List[dict]]): Una lista opcional de metadatos asociados a los documentos.\n",
    "* ids (Optional[List[str]]): Una lista opcional de identificadores para los documentos.\n",
    "* namespace (Optional[str]): Un espacio de nombres opcional para agregar los documentos al vectorstore.\n",
    "* index_name (Optional[str]): El nombre opcional del índice de Pinecone al que se agregarán los documentos.\n",
    "* upsert_kwargs (Optional[dict]): Argumentos opcionales adicionales para el método upsert utilizado para agregar los documentos al vectorstore.\n",
    "* pool_threads (int): El número de subprocesos en el grupo de subprocesos utilizado para agregar los documentos al vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.pinecone.Pinecone at 0x1f757b9fa10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pinecone.from_documents(\n",
    "    chunks,\n",
    "    embeddings,\n",
    "    index_name=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QaN\n",
    "\n",
    "load_qa_chain es una función en la biblioteca Langchain que se utiliza para cargar una cadena de procesamiento de preguntas y respuestas (QA). Aquí están los parámetros que se pueden pasar a esta función:\n",
    "\n",
    "* llm (BaseLanguageModel): El modelo de lenguaje que se utilizará en la cadena de QA.\n",
    "* chain_type (str): El tipo de cadena de combinación de documentos que se utilizará en la cadena de QA. Puede ser \"stuff\", \"map_reduce\", \"refine\" o \"map_rerank\".\n",
    "* verbose (Optional[bool]): Indica si se ejecutarán las cadenas en modo detallado o no.\n",
    "* **kwargs (Any): Argumentos adicionales que se pueden pasar a la función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de cadenas QaN\n",
    "\n",
    "* \"stuff\": Este tipo de cadena de combinación de documentos utiliza un enfoque simple de concatenación de documentos. Los documentos se combinan en un solo texto y se envían al modelo de lenguaje para generar una respuesta.\n",
    "\n",
    "* \"map_reduce\": Este tipo de cadena utiliza un enfoque de map-reduce para combinar documentos. Los documentos se dividen en fragmentos más pequeños y se envían al modelo de lenguaje en paralelo. Luego, las respuestas parciales se combinan utilizando una función de reducción para generar una respuesta final.\n",
    "\n",
    "* \"refine\": Este tipo de cadena utiliza un enfoque de refinamiento iterativo. Los documentos se combinan inicialmente utilizando el enfoque \"stuff\" y se genera una respuesta inicial. Luego, se realiza un proceso de refinamiento iterativo donde se seleccionan y agregan documentos adicionales para mejorar la respuesta.\n",
    "\n",
    "* \"map_rerank\": Este tipo de cadena utiliza un enfoque de map-reduce con reranking. Los documentos se dividen en fragmentos y se envían al modelo de lenguaje en paralelo. Luego, las respuestas parciales se clasifican y se selecciona la mejor respuesta utilizando un algoritmo de reranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instacia de la base da dato de vectq\n",
    "vstore = Pinecone.from_existing_index(INDEX_NAME, embeddings)\n",
    "\n",
    "# carga de los modelos\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo')\n",
    "chainQA = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta a realizar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregunta = \"Mi amigo tom es muy fanatico del malago fc sabes que podria regalarle?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta en la base de datos\n",
    "\n",
    "``similarity_search`` es un método en la clase Pinecone de la biblioteca Langchain que se utiliza para buscar documentos similares a una consulta dada en un vectorstore de Pinecone. Aquí están los parámetros que se pueden pasar a este método:\n",
    "\n",
    "* query (str): El texto de la consulta para buscar documentos similares.\n",
    "* k (int): El número de documentos similares que se deben devolver. El valor predeterminado es 4.\n",
    "* filter (Optional[dict]): Un diccionario opcional de argumentos para filtrar los resultados basados en metadatos.\n",
    "* namespace (Optional[str]): El espacio de nombres opcional en el que se debe realizar la búsqueda. El valor predeterminado es None, lo que significa que se buscará en todos los espacios de nombres.\n",
    "\n",
    "Es importante tener en cuenta que la similitud se calcula utilizando la métrica de similitud especificada al crear el índice de Pinecone, que puede ser \"cosine\" u otra métrica compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me traera los 3 documentos similares\n",
    "\n",
    "docs = vstore.similarity_search(pregunta, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='HISTORIA DEL CLUB\\nLos orígenes del fútbol malagueño se remontan a 1904. En 1941, con la inauguración de La Rosaleda, nace el C.D. Málaga. En 1994 coge su testigo el Málaga Club de Fútbol, consiguiendo los mejores resultados deportivos de la historia. Gana la Intertoto en 2002 y disputa la Copa de la UEFA en la 2002/03. Bajo la presidencia de Sheikh Abdullah Al Thani, y tras la histórica cuarta plaza obte-nida en la temporada 2011/12, la entidad de Martiricos disputa la Champions League, alcanzando los cuartos de final.Málaga CFCÓMO LLEGAR AL ESTADIO\\nEstadio La Rosaleda,Paseo de Martiricos s/n 29011, Málaga\\nParking Centro ComercialRosaleda\\nLínea 15 (Paradas 1505 y 1570)\\nEstación Málaga María Zambrano (LD 2.8 km) Estación Málaga-Centro Alameda (MD 2.1 km)\\nAeropuerto de Málaga', metadata={'page': 0.0, 'source': 'la-rosaleda_v3.pdf'}),\n",
       " Document(page_content='Localización ventanilla de incidencias y email de \\natención al espectador\\nVentanilla de incidencias: taquillas del estadio.\\nAtención al espectador: ticketing@malagacf.es\\nSERVICIOS DEL ESTADIO\\nBares: 24 barras distribuidas junto a los accesos. \\nTienda: en la fachada exterior (esq. Tribuna con Gol).\\nPágina web y otros datos de interés\\nwww.malagacf.com | Teléfono: 952 61 37 37\\nYouTube: https://www.youtube.com/user/MalagaCFTV\\nTwitter: @MalagaCFFacebook: https://www.facebook.com/MalagaCF/Instagram: @malagacf', metadata={'page': 1.0, 'source': 'la-rosaleda_v3.pdf'}),\n",
       " Document(page_content='Bienvenidos a La Rosaleda. \\nEl recinto blanquiazul, con más de 75 años de  historia, es la casa del primer equipo de la capital de la Costa del Sol desde su inauguración en 1941. Ubicado en el Paseo de Martiricos, el campo malaguista tiene un aforo superior a los 30.000 espectadores, habiendo remodelado y modernizado sus instalaciones en los últimos años.El estadio del Málaga C.F. incluye el complejo sanitario Clínicas Rincón y un atractivo Museo&Tour, que recorre las entrañas de una Rosaleda que ha honrado alguna de sus puertas de acceso renombrándolas con exjugadores de  la Entidad.\\nHISTORIA DEL CLUB', metadata={'page': 0.0, 'source': 'la-rosaleda_v3.pdf'})]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos la respues a la cadena QN definida previamente\n",
    "\n",
    "Pintamos la respues junto con los detalles de la operacion a OpenIa para saber su costo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta ChatGPT: El Málaga Club de Fútbol ha ganado una Copa Intertoto en el año 2002. \n",
      " Tokens Used: 776\n",
      "\tPrompt Tokens: 676\n",
      "\tCompletion Tokens: 100\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0012140000000000002\n",
      "Mi amigo tom es muy fanatico del malago fc sabes que podria regalarle? [Document(page_content='HISTORIA DEL CLUB\\nLos orígenes del fútbol malagueño se remontan a 1904. En 1941, con la inauguración de La Rosaleda, nace el C.D. Málaga. En 1994 coge su testigo el Málaga Club de Fútbol, consiguiendo los mejores resultados deportivos de la historia. Gana la Intertoto en 2002 y disputa la Copa de la UEFA en la 2002/03. Bajo la presidencia de Sheikh Abdullah Al Thani, y tras la histórica cuarta plaza obte-nida en la temporada 2011/12, la entidad de Martiricos disputa la Champions League, alcanzando los cuartos de final.Málaga CFCÓMO LLEGAR AL ESTADIO\\nEstadio La Rosaleda,Paseo de Martiricos s/n 29011, Málaga\\nParking Centro ComercialRosaleda\\nLínea 15 (Paradas 1505 y 1570)\\nEstación Málaga María Zambrano (LD 2.8 km) Estación Málaga-Centro Alameda (MD 2.1 km)\\nAeropuerto de Málaga', metadata={'page': 0.0, 'source': 'la-rosaleda_v3.pdf'}), Document(page_content='Localización ventanilla de incidencias y email de \\natención al espectador\\nVentanilla de incidencias: taquillas del estadio.\\nAtención al espectador: ticketing@malagacf.es\\nSERVICIOS DEL ESTADIO\\nBares: 24 barras distribuidas junto a los accesos. \\nTienda: en la fachada exterior (esq. Tribuna con Gol).\\nPágina web y otros datos de interés\\nwww.malagacf.com | Teléfono: 952 61 37 37\\nYouTube: https://www.youtube.com/user/MalagaCFTV\\nTwitter: @MalagaCFFacebook: https://www.facebook.com/MalagaCF/Instagram: @malagacf', metadata={'page': 1.0, 'source': 'la-rosaleda_v3.pdf'}), Document(page_content='Bienvenidos a La Rosaleda. \\nEl recinto blanquiazul, con más de 75 años de  historia, es la casa del primer equipo de la capital de la Costa del Sol desde su inauguración en 1941. Ubicado en el Paseo de Martiricos, el campo malaguista tiene un aforo superior a los 30.000 espectadores, habiendo remodelado y modernizado sus instalaciones en los últimos años.El estadio del Málaga C.F. incluye el complejo sanitario Clínicas Rincón y un atractivo Museo&Tour, que recorre las entrañas de una Rosaleda que ha honrado alguna de sus puertas de acceso renombrándolas con exjugadores de  la Entidad.\\nHISTORIA DEL CLUB', metadata={'page': 0.0, 'source': 'la-rosaleda_v3.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    response = chainQA.run(input_documents=docs, question=pregunta)\n",
    "    print(f\"Respuesta ChatGPT: {respuesta} \\n {cb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QnA con memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos la memoria conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Creamos el template del promt\n",
    "template = \"\"\"Eres un chatbot manteniendo una conversación con un humano.\n",
    "\n",
    "Dadas las siguientes partes extraídas de un documento largo y el historial de la conversacion, crea una respuesta final para la pregunta del Human,\n",
    "Si la respuesta final no se cuentra en el las partes extraídas de un documento largo o en el historial de la conversacion tienes que decir \"Lo siento no tengo esa informacion\".\n",
    "\n",
    "## Partes del documento largo\n",
    "{context}\n",
    "\n",
    "## Historial de la conversación\n",
    "{chat_history}\n",
    "\n",
    "## Pregunta del Human y respuesta final\n",
    "Human: {human_input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template\n",
    ")\n",
    "\n",
    "# Creamos la memoria\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos la memoria a la cadena QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainQnAMemory = load_qa_chain(\n",
    "    OpenAI(temperature=0), chain_type=\"stuff\", memory=memory, prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizamos una convercion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 1462\n",
      "\tPrompt Tokens: 1447\n",
      "\tCompletion Tokens: 15\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.029240000000000002\n"
     ]
    }
   ],
   "source": [
    "# Variable conde se guarda el historial\n",
    "with get_openai_callback() as cb:\n",
    "    pregunta = \"Crea una porra usando los inventos de nicola tesla\"\n",
    "    docs = vstore.similarity_search(pregunta, 3)\n",
    "    response = chainQnAMemory({\"input_documents\": docs, \"human_input\": pregunta})\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Sabes cual es mi nombre?\n",
      "AI:  Lo siento, no tengo esa información.\n",
      "Human: mi nombre es Daniel, necsito darle un regalo a mi amigo tom\n",
      "AI:  Puedes visitar la tienda de la Rosaleda, ubicada en la fachada exterior (esquina Tribuna con Gol). También puedes visitar la página web del Málaga C.F. para obtener más información sobre el club y sus productos.\n",
      "Human: Puedes llamar me por mi nombre?, a mi amigo le gusta la ropa donde puedo comprarla?\n",
      "AI:  Hola Daniel, sí, puedo llamarte por tu nombre. Para comprar ropa para tu amigo, puedes visitar la tienda de la Rosaleda, ubicada en la fachada exterior (esquina Tribuna con Gol). También puedes visitar la página web del Málaga C.F. para obtener más información sobre el club y sus productos.\n",
      "Human: Crea una porra usando el nombre de mi amigo\n",
      "AI:  ¡Vamos Tom! ¡Vamos Málaga!\n",
      "Human: Crea una porra usando los inventos de nicola tesla\n",
      "AI:  Lo siento, no tengo esa información.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['chat_history'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
